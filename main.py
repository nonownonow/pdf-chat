import os
import streamlit as st
from dotenv import load_dotenv
from pdf_summary_service import extract_pdf_text, chat_with_gpt, chat_with_exaone

load_dotenv()

st.set_page_config(page_title="PDF ì±„íŒ…", page_icon="ğŸ“„")

# â”€â”€ Session State ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "pdf_text" not in st.session_state:
    st.session_state.pdf_text = None
if "pdf_name" not in st.session_state:
    st.session_state.pdf_name = None

# â”€â”€ Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ì„¤ì •")

    model_choice = st.radio("ëª¨ë¸ ì„ íƒ", ["GPT-4.1-mini", "EXAONE 3.5"])

    if model_choice == "GPT-4.1-mini":
        openai_key = st.text_input(
            "OpenAI API Key",
            value=os.getenv("OPEN_AI_API", ""),
            type="password",
        )
    else:
        exaone_key = st.text_input(
            "EXAONE API Key (Friendli)",
            value=os.getenv("EXAONE_API", ""),
            type="password",
        )
        exaone_model = st.text_input(
            "EXAONE Model ID",
            value=os.getenv("EXAONE_MODEL_ID", ""),
        )

    st.divider()
    uploaded_file = st.file_uploader("PDF ì—…ë¡œë“œ", type=["pdf"])

    if uploaded_file is not None and uploaded_file.name != st.session_state.pdf_name:
        with st.spinner("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
            st.session_state.pdf_text = extract_pdf_text(uploaded_file.read())
            st.session_state.pdf_name = uploaded_file.name
            st.session_state.messages = []

    if st.session_state.pdf_name:
        st.success(f"{st.session_state.pdf_name}")

    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.rerun()

# â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("PDF ì±„íŒ…")

if not st.session_state.pdf_text:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ ëŒ€í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

# ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("PDFì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”"):
    # í‚¤ ê²€ì¦
    if model_choice == "GPT-4.1-mini" and not openai_key:
        st.warning("OpenAI API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    if model_choice == "EXAONE 3.5" and (not exaone_key or not exaone_model):
        st.warning("EXAONE API Keyì™€ Model IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°)
    with st.chat_message("assistant"):
        if model_choice == "GPT-4.1-mini":
            stream = chat_with_gpt(
                st.session_state.pdf_text,
                st.session_state.messages,
                openai_key,
            )
        else:
            stream = chat_with_exaone(
                st.session_state.pdf_text,
                st.session_state.messages,
                exaone_key,
                exaone_model,
            )

        response = st.write_stream(stream)

    st.session_state.messages.append({"role": "assistant", "content": response})
